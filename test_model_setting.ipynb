{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, StableDiffusionPipeline\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler, PNDMScheduler, DDIMPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_path = \"/home/v-yuancwang/AudioEditing/diffusion_configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae = AutoencoderKL.from_pretrained(\"/blob/v-yuancwang/AudioEditing/Finetune_VAE_2/checkpoint-110000\", subfolder=\"vae\")\n",
    "vae = AutoencoderKL.from_config(configs_path, subfolder=\"vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn(1, 1, 80, 624)\n",
    "print(vae(test).sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel.from_config(configs_path, subfolder=\"unet\")\n",
    "temp = torch.randn((1, 8, 78, 10))\n",
    "t = 1\n",
    "e = torch.randn((1, 10, 768))\n",
    "print(unet(temp, t, e).sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizer, CLIPTextModel, BertTokenizer, BertModel, AutoTokenizer, T5EncoderModel, T5TokenizerFast, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "text_encoder = T5EncoderModel.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "# text_encoder = BertModel.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"/blob/v-yuancwang/AudioEditing/MyPipeline\",\n",
    "    vae=vae,\n",
    "    unet=unet,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "pipeline.save_pretrained(\"/home/v-yuancwang/AudioEditing/MyPipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16 (default, Jan 17 2023, 22:20:44) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ee27c2a92f1fff136d50aad92bfca040aea835edd9bacd8b4c989384ca9eab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
